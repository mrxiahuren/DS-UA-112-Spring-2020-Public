{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ea1eabc3ed353c2b1bc4e652a4f8ded",
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## Project 1\n",
    "\n",
    "- ### Release Date: Monday, March 16\n",
    "- ### Due Date: Monday April 6, 12:00 PM\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this project, we will work with social media data to analyze politics. Along the way, we want to learn more about [data-driven journalism](https://en.wikipedia.org/wiki/Data-driven_journalism) where journalists use datasets for reporting. Journalists will locate information, filter and transform tables, generate charts and perform investigations for news outlets.\n",
    "\n",
    "We want to gain insights into politics through data. We will try to reproduce some of the findings from [Buzzfeed](https://www.buzzfeednews.com/article/peteraldhous/trump-twitter-wars) on the usage of Twitter by the president. Note that the journalists have provided [supporting details](https://buzzfeednews.github.io/2018-01-trump-twitter-wars/) of their analyses alongside the article. \n",
    "\n",
    "As we explore the data, we want to gain practice with:\n",
    "* Searching for patterns of characters in strings  \n",
    "* Working with data in nested formats instead of tabular formats\n",
    "* Handling dates and times\n",
    "\n",
    "We will guide you through the problems step by step. However, we encourage you to discuss with us in Office Hours and on Piazza so that we can work together through these steps. \n",
    "\n",
    "#### Submission Instructions\n",
    "\n",
    "Submission of homework requires two steps. See **Homework 0** for more information.\n",
    "\n",
    "##### _Step 1_\n",
    "You are required to **submit your notebook on JupyterHub**. Please navigate to the `Assignments` tab to  \n",
    "- fetch\n",
    "- modify \n",
    "- validate\n",
    "- submit \n",
    "\n",
    "your notebook. Consult the [instructional video](https://nbgrader.readthedocs.io/en/stable/user_guide/highlights.html#student-assignment-list-extension-for-jupyter-notebooks) for more information about JupyterHub.\n",
    "\n",
    "##### _Step 2_\n",
    "You are required to **submit a copy of your notebook to Gradescope**. Follow these steps\n",
    "\n",
    "##### _Formatting Instructions_\n",
    "\n",
    "\n",
    "1. Download as HTML (`File->Download As->HTML(.html)`). \n",
    "1. Open the HTML in the browser. Print to .pdf \n",
    "1. Upload to Gradescope. Consult the [instructional video](https://www.gradescope.com/get_started#student-submission) for more information about Gradescope. \n",
    "1. Indicate the location of your responses on Gradescope. You must tag your answer's page numbers to the appropriate question on Gradescope. See instructional video for more information.\n",
    "\n",
    "Note that \n",
    "\n",
    "- You should break long lines of code into multiple lines. Otherwise your code will extend out of view from the cell. Consider using `\\` followed by a new line. \n",
    "- For each textual response, please include relevant code that informed your response. \n",
    "- For each plotting question, please include the code used to generate the plot. If your plot does not appear in the HTML / pdf output, then use `Image('name_of_file', embed = True)` to embed it.\n",
    "- You should not display large output cells such as all rows of a table. \n",
    "\n",
    "**Important**: Gradescope points will be awarded if and only if all the formatting instructions are followed. \n",
    "\n",
    "#### Collaboration Policy\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the homework, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** *list name here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NetId:** *list netid here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators:** *list names here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8586d57d706ab182d94a8297313e63c3",
     "grade": false,
     "grade_id": "cell-7f3ef944c7d1d645",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Rubric\n",
    "\n",
    "Question | Points\n",
    "--- | ---\n",
    "Gradescope | 2 \n",
    "1a | 1\n",
    "1b | 1\n",
    "1c | 2\n",
    "2a | 2\n",
    "2b | 1\n",
    "2c | 1\n",
    "2d | 1\n",
    "2e | 1\n",
    "3a | 1\n",
    "3b | 1\n",
    "3c | 1\n",
    "3d | 1\n",
    "3e | 1\n",
    "3f | 1\n",
    "4a | 1\n",
    "4b | 2\n",
    "Total | 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c31fefd3bc8dff35e77e072000625d6e",
     "grade": false,
     "grade_id": "cell-a324406191a9b27b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "import dsua_112_utils\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set some parameters in the packages \n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "\n",
    "pd.options.display.max_rows = 20  \n",
    "pd.options.display.max_columns = 15\n",
    "\n",
    "# Some packages to help with configuration\n",
    "import os, sys, pathlib, pickle\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53e918066e922d3ff42525d6f2d018a5",
     "grade": false,
     "grade_id": "cell-d9a5b12b8674f356",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "home_path = os.environ[\"HOME\"]\n",
    "data_path_recent = f'{home_path}/shared/Project1/data/trump_tweets_recent.json' \n",
    "data_path_old_1 = f'{home_path}/shared/Project1/data/old_trump_tweets_1.json'\n",
    "data_path_old_2 = f'{home_path}/shared/Project1/data/old_trump_tweets_2.json'\n",
    "img_path = f'{home_path}/shared/Project1/images'\n",
    "lexicon_path = f'{home_path}/shared/Project1/vader_lexicon.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "50b83ce6131eac41ba6242da3168cd7e",
     "grade": true,
     "grade_id": "cell-233346e9b4c8075f",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert 'pandas' in sys.modules and \"pd\" in locals()\n",
    "assert 'numpy' in sys.modules and \"np\" in locals()\n",
    "assert 'matplotlib' in sys.modules and \"plt\" in locals()\n",
    "assert 'seaborn' in sys.modules and \"sns\" in locals()\n",
    "assert 'datetime' in sys.modules \n",
    "assert \"home_path\" in locals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2acc25f2511e60cae91ad0ca8ddf1248",
     "grade": false,
     "grade_id": "cell-fab098ea1af2168c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Loading Twitter Data\n",
    "\n",
    "\n",
    "Donald Trump has made frequent use of Twitter. We want to focus on activity linked to his Twitter handle `realdonaldtrump`. After we access the data, we can try to understand the scope and temporality of the posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "125abc0cf022c63766203bd074eb25c0",
     "grade": false,
     "grade_id": "cell-1c9da2102f535dfe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=img_path + '/usage.PNG', embed=True, width=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "950b126a762f1c6666089de4b7323430",
     "grade": false,
     "grade_id": "cell-7442dcfec335a749",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1a\n",
    "\n",
    "Recall from Section 7 that Twitter provides an Application Programming Interface (API) for developers. We can access the API with the `tweepy` package. With Twitter credentials we can collect data from the platform in the Javascript Object Notation (JSON) format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3970c191a45f53140d43ec381ef086ea",
     "grade": false,
     "grade_id": "cell-da0e58720b0f1e56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run to load the data\n",
    "\n",
    "with open(data_path_recent) as f: \n",
    "    trump_tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "36b364934f5b20348cbd09bca4397f71",
     "grade": false,
     "grade_id": "2ax-conclusion",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We have collected the last 2000 tweets from `realdonaldtrump` into `trump_tweets_recent.json`. We can load files in the JSON format with the `json` package. Remember that the JSON format is a nested format not a tabular format. Instead of rows and columns, we have keys and values resembling a dictionary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4fbe8583cb70683d096119e32cd6245",
     "grade": true,
     "grade_id": "cell-0539720dcbe23d78",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert 2000 <= len(trump_tweets) <= 3000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38be1aaa2f28846f0d165b33d17b8067",
     "grade": false,
     "grade_id": "cell-56a3c8f1a3d52b80",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Here we have a list of dictionaries. Each dictionary corresponds to a post. \n",
    "\n",
    "Note that Twitter limits the usages of its API. We will see in Question 2e that the data contains gaps stemming from restrictions on access. Since we cannot collect all post from Twitter, we need to combine with historical data stored in separate files. \n",
    "\n",
    "Before we link these records, we want to study `trump_tweets`. In particular, what is the oldest tweet in  `trump_tweets`. We have the following keys for each posts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "390d92f9738353c73112c5ec23638ed5",
     "grade": false,
     "grade_id": "cell-fcd56ca47aad711d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "list(trump_tweets[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "071985f92cb92f9ba8d501941eab4e81",
     "grade": false,
     "grade_id": "cell-15350454090a2690",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The key `created_at` corresponds to the date, time and timezone for the post. Create a list consisting of the values for `created_at` for each of the entries in the `trump_tweets`. Use the `pandas` function `to_datetime` to convert the list into a `DatetimeIndex`. See Lab 7 for more information about storing dates and times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2065f0f8ab06a578eebb4a0f773a880d",
     "grade": false,
     "grade_id": "cell-4acf31805b956414",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "list_datetime = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "index_datetime = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "972c27ff9b915d5f4a8ab759aa40786e",
     "grade": true,
     "grade_id": "cell-2d5b8a45f2fa88b0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "assert str(index_datetime.tz) == \"UTC\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6883cd33db76e18ab2301d25c7639904",
     "grade": false,
     "grade_id": "cell-31c60936bcf8fa4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note that each entry is of the form `YYYY-MM-DD HH:MM:SS+TZ` corresponding to \n",
    "\n",
    "- `YYYY`: 4 digit year\n",
    "- `MM`: 2 digit month\n",
    "- `DD`: 2 digit day\n",
    "- `HH`: 2 digit hour\n",
    "- `MM`: 2 digit minute\n",
    "- `SS`: 2 digit second\n",
    "- `DD`: timezone as 4 digit offset from [UTC timezone](https://www.wikiwand.com/en/List_of_UTC_time_offsets)\n",
    "\n",
    "Determine the year and month of the oldest tweet. Remember from Lab 7 that objects storing dates have attributes `year` and `month`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "88749c66c50a4df56336f903d44387ca",
     "grade": false,
     "grade_id": "q1-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Enter the year of the oldest tweet \n",
    "\n",
    "oldest_year = ... \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Enter the month of the oldest tweet (e.g. 1 for January)\n",
    "\n",
    "oldest_month = ... \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82d8b4b4232e936e6c1e05b53519d5a2",
     "grade": true,
     "grade_id": "q1-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "assert type(oldest_month) == int\n",
    "assert 1<= oldest_month <= 12\n",
    "\n",
    "assert type(oldest_year) == int\n",
    "assert oldest_year <= 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "deafd72c08709a1971b5a6ae158566bd",
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 1b\n",
    "\n",
    "Usign the Twitter API, we could collect more data. We have called these files `old_trump_tweets_1.json` and `old_trump_tweets_2.json`. We need to join these files with the information in  `trump_tweets_recent.json`. Note that we have a nested format of data not a tabular format of data. We cannot use the joining operations to combine the files. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3a25b786277c5e1c22f981a34ee85ba5",
     "grade": false,
     "grade_id": "cell-1b3f5e1cfb92b3fa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run to load additional data \n",
    "\n",
    "with open(data_path_old_1) as f:\n",
    "    old_trump_tweets_1 = json.load(f)\n",
    "\n",
    "with open(data_path_old_2) as f:\n",
    "    old_trump_tweets_2 = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf41b7b8baed74214f692cad70dcb43d",
     "grade": false,
     "grade_id": "cell-d72e4aa46479baab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We want to combine the data from `old_trump_tweets_1`, `old_trump_tweets_2` and `trump_tweets_recent`. However, some posts will store the text in the `text` field and others will use the `full_text` field.\n",
    "\n",
    "For each entry in the lists `old_trump_tweets_1`, `old_trump_tweets_2` and `trump_tweets_recent` containing `full_text`, replace the key `full_text` with `text`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f162a35dfa71d5bf0686aa972d13fd74",
     "grade": false,
     "grade_id": "cell-fa9dbd8d438a36a2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for tweets in [trump_tweets, old_trump_tweets_1, old_trump_tweets_2]:\n",
    "    for tweet in tweets:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b14c7743b6a6bbb4acfbb073df251040",
     "grade": true,
     "grade_id": "cell-378128a3737f6ce4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert \"full_text\" not in [tweet.keys() for tweet in trump_tweets]\n",
    "assert \"full_text\" not in [tweet.keys() for tweet in old_trump_tweets_1]\n",
    "assert \"full_text\" not in [tweet.keys() for tweet in old_trump_tweets_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ba8ef5434c49422cdda27e89bb965aaa",
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    " Generate a DataFrame called `all_tweets` with columns\n",
    "\n",
    "- `id`: Unique identifier of the tweet\n",
    "- `time`: The date, time and timezone of the post from the `created_at` column \n",
    "- `source`: The source device of the tweet.\n",
    "- `text` or `full_text`: The text in the post\n",
    "- `retweet_count`: The retweet count of the tweet \n",
    "\n",
    "Note that we can create a DataFrame by passing a list of dictionaries to `pd.DataFrame`. Here we need the keys to match for each dictionary. Generate three DataFrames corresponding to `old_trump_tweets_1`, `old_trump_tweets_2` and `trump_tweets_recent`. Combine them using `pd.concat`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d78248d4948d1557fafb4a73e4ea161d",
     "grade": false,
     "grade_id": "cell-ba2451c0afe779ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "columns = ['created_at', 'id', \"text\", 'source', 'retweet_count']\n",
    "\n",
    "list_df = []\n",
    "for tweets in [trump_tweets, old_trump_tweets_1, old_trump_tweets_2]:\n",
    "    df = ...\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    list_df.append(df)    \n",
    "\n",
    "all_tweets = pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ca69c8d1572682af40550a773fd59aa7",
     "grade": true,
     "grade_id": "cell-4a08f3dd38ccaa88",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert set(all_tweets.columns.values).issubset(set(['time', 'id', 'text', 'source', 'retweet_count']))\n",
    "assert all_tweets.shape[1] == 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99ad4c45ae5e4b33ecc1449acffdf3a9",
     "grade": false,
     "grade_id": "cell-df173ffd1363a06b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 1c\n",
    "\n",
    "Note that we have duplicates in the `id` columns because `old_trump_tweets_1`, `old_trump_tweets_2` and `trump_tweets_recent` contained overlapping posts. We can remove duplicates through \n",
    "\n",
    "1. Grouping by `id` column \n",
    "1. Using the method `first` to select the first row from each group\n",
    "\n",
    "Call the resulting table `trump`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea99385fff44a2bff646a75f16b281be",
     "grade": false,
     "grade_id": "cell-34da0c8f5ac009dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "trump = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3e7aabd252fcdeebf5c7ae2d0020c5c8",
     "grade": true,
     "grade_id": "cell-ad68779b23f2c9db",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert len(trump.index.values) == len(np.unique(trump.index.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f8bdc6de78fa357e8f4a9e6c1f906686",
     "grade": false,
     "grade_id": "cell-b23d6323ede587ad",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Before moving onto the analysis of the dataset\n",
    "\n",
    "1. Sort the rows of `trump` by the values in the index using the `pandas` method `sort_index`. \n",
    "1. Use the `pandas` method `pd.to_datetime` on the `time` column to convert the entries like in Question 1a.  \n",
    "1. Use `pd.to_csv` to save a copy to the path `/tmp/trump.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfc241a78f7e4381fdabf1942301b94c",
     "grade": false,
     "grade_id": "q3-ans",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d65b6c5944488d973e1d1c77e55fec41",
     "grade": true,
     "grade_id": "q3-test",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "test",
     "q03"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "assert 11000 < trump.shape[0] < 12000\n",
    "assert 831846101179314177 in trump.index\n",
    "assert np.any([('Twitter for iPhone' in s) for s in trump['source'].unique()])\n",
    "assert str(trump[\"time\"].dt.tz) == \"UTC\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "707b3c18b799265db0956d2266dbfa0b",
     "grade": false,
     "grade_id": "question4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 2: Tweet Source Analysis\n",
    "\n",
    "We want to study some of the charateristics of Trump tweets. In particular, we want to determine the devices used for the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6afb6dfe20e5154416906478ba3d9384",
     "grade": false,
     "grade_id": "unique-sources",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91faccc06f2f811d11a39fd9c69f4d59",
     "grade": false,
     "grade_id": "q4a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 2a\n",
    "\n",
    "We want to remove the HTML tags from the entries in the `source` column. Use `trump['source'].str.replace` with a regular expression. Remember that regular expressions are greedy meaning that `r\"<.*>\"` will match the entire entry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c877a2a3241bd02edb941b53c9b96a4",
     "grade": false,
     "grade_id": "q4a-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16ae558416f978dbf3e8ee7769e15553",
     "grade": true,
     "grade_id": "q4a-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert set(['Twitter for Android','Twitter for iPhone']) < set(trump['source'].unique())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fbd18f3db9b76174657bbfadec0dede6",
     "grade": false,
     "grade_id": "note-about-device-usage",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "We can see in the following plot that there are two device types that are more commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73e35660867bf196519a525894bd6016",
     "grade": false,
     "grade_id": "device-usage-plot",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['source'].value_counts().plot(kind=\"bar\")\n",
    "plt.ylabel(\"Number of Tweets\")\n",
    "q2a_gca = plt.gca();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dada0e5a0ea5cae2bd78d0d03e3c15a3",
     "grade": true,
     "grade_id": "cell-eec4320e7675a543",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "\n",
    "heights = [int(rect.get_height()) for rect in q2a_gca.get_children() if isinstance(rect, matplotlib.patches.Rectangle)]\n",
    "assert max(heights) == max(trump['source'].value_counts().values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5f1f65f35be880974004ba394e524f6c",
     "grade": false,
     "grade_id": "cell-7eed9f3244693e35",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Question 2b\n",
    "\n",
    "Is there a difference between his Tweet behavior across these devices? Maybe Trump's tweets from an Android come at different times than his tweets from an iPhone. Note that Twitter gives us his tweets in the [UTC timezone](https://www.wikiwand.com/en/List_of_UTC_time_offsets). We see the `+0000` in the `time` column.\n",
    "\n",
    "Add a column `est_time` by converting from UTC to EST timezone. Use `trump['time'].dt.tz_convert(\"US/Eastern\")`. See Lab 7 for more information about time zones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7fce153a8233701feea888dc50e619cb",
     "grade": false,
     "grade_id": "q4b",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Convert to Eastern Time\n",
    "\n",
    "trump['est_time'] = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e30db0d3dc50686ea6e8cf882816fae",
     "grade": true,
     "grade_id": "cell-7af77262c2894492",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert str(trump[\"est_time\"].dt.tz) == \"EST\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b-answer",
     "locked": false,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [
     "student"
    ]
   },
   "source": [
    "Now add a column called `hour` to the `trump` table. The colum should contain the hour of the day as floating point number computed by:\n",
    "\n",
    " $$\\text{hour} + \\frac{\\text{minute}}{60} + \\frac{\\text{second}}{60^2} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e86f64aaef2914caeb947936a7fdecb7",
     "grade": false,
     "grade_id": "q4b-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump['hour'] = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "46e2f53f541dfcab5bb1b9b5c2652070",
     "grade": true,
     "grade_id": "q4b-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "test",
     "q04a"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert max(trump['hour']) > 23\n",
    "assert sum(trump['hour'] < 0) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05b568298e06132538f9e1be3d397dfd",
     "grade": false,
     "grade_id": "q4c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 2c\n",
    "\n",
    "Use this data along with the seaborn `distplot` function to examine the distribution over hours of the day in eastern time that trump tweets on each device for the 2 most commonly used devices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "278b772d07a1007f846e2c6a38ff33e7",
     "grade": false,
     "grade_id": "cell-f2ba0ae03b31600c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_devices = trump['source'].value_counts().sort_values()[-2:].index.values\n",
    "\n",
    "for device in top_devices:\n",
    "    series = ...\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    sns.distplot(series, hist=False, label = device[-7:] )    \n",
    "    \n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('fraction')\n",
    "plt.legend()\n",
    "q2c_gca = plt.gca();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df947c5112ff957dc0b5a9bac44cfb94",
     "grade": true,
     "grade_id": "cell-0785557277e0f1b6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "with open(f\"{home_path}/shared/Project1/data/image.pickle\", \"br\") as fh:\n",
    "    q2c_gca_benchmark = pickle.load(fh)\n",
    "\n",
    "curves = dsua_112_utils.get_curves(q2c_gca)\n",
    "benchmark_curves = dsua_112_utils.get_curves(q2c_gca_benchmark)\n",
    "\n",
    "diff = dsua_112_utils.generate_normalized_difference(q2c_gca_benchmark, curves[\"Android\"], benchmark_curves['Android'])\n",
    "dsua_112_utils.compare_curves(diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9293f0be042cdd67fbcae5ea564f5bf6",
     "grade": false,
     "grade_id": "q4d",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "\n",
    "### Question 2d\n",
    "\n",
    "According to [this Verge article](https://www.theverge.com/2017/3/29/15103504/donald-trump-iphone-using-switched-android), Donald Trump switched from an Android to an iPhone sometime in March 2017.\n",
    "\n",
    "Create a figure identical to your figure from 4c, except that you should show the results only from 2016. If you get stuck consider looking at the `year_fraction` function from the next problem.\n",
    "\n",
    "During the campaign, it was theorized that Donald Trump's tweets from Android were written by him personally, and the tweets from iPhone were from his staff. Does your figure give support to this theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "312c8b47ff8561ea726c8cd403b73cc6",
     "grade": false,
     "grade_id": "cell-27e446fb26e6fd56",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_devices = trump['source'].value_counts().sort_values()[-2:].index.values\n",
    "\n",
    "for device in top_devices:\n",
    "    series = ...\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    sns.distplot(series, hist=False, label = device[-7:] )    \n",
    "    \n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('fraction')\n",
    "plt.legend()\n",
    "q2d_gca = plt.gca();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82526cec202c9fc072e19c5b24028061",
     "grade": true,
     "grade_id": "cell-4c973f28d0237ca1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "with open(f\"{home_path}/shared/Project1/data/image1.pickle\", \"br\") as fh:\n",
    "    q2d_gca_benchmark = pickle.load(fh)\n",
    "\n",
    "curves = dsua_112_utils.get_curves(q2d_gca)\n",
    "benchmark_curves = dsua_112_utils.get_curves(q2d_gca_benchmark)\n",
    "\n",
    "diff = dsua_112_utils.generate_normalized_difference(q2d_gca_benchmark, curves[\"Android\"], benchmark_curves['Android'])\n",
    "dsua_112_utils.compare_curves(diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e5af1d9a75ba6c7484010e2aae2041ae",
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 2e\n",
    "\n",
    "Which device did Donald Trump use between 2016-2018 in this dataset. To examine the distribution of dates we will convert the date to a fractional year that can be plotted as a distribution. We will use the `year_fraction` function in the supporting code for the assignment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3753e66344a958b15616b7b117d091d5",
     "grade": false,
     "grade_id": "fractional-year",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['year'] = trump['time'].apply(dsua_112_utils.year_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3ab1efe0722d73d6eb24080d50893037",
     "grade": false,
     "grade_id": "q5a",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Use the `sns.distplot` to overlay the distributions of the 2 most frequently used web technologies between before 2019. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d5c4a7cf3f4e42bff916ba76f307382",
     "grade": false,
     "grade_id": "cell-d5403ba76c15d6bf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "top_devices = trump['source'].value_counts().sort_values()[-2:].index.values\n",
    "\n",
    "for device in top_devices:\n",
    "    series = ...\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    sns.distplot(series, hist=False, label = device[-7:] )    \n",
    "    \n",
    "plt.xlabel('hour')\n",
    "plt.ylabel('fraction')\n",
    "plt.legend()\n",
    "q2e_gca = plt.gca();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f0e6348d5d8266df979b26f1095bf12",
     "grade": true,
     "grade_id": "cell-3ccebceaf05b0496",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "with open(f\"{home_path}/shared/Project1/data/image2.pickle\", \"br\") as fh:\n",
    "    q2e_gca_benchmark = pickle.load(fh)\n",
    "\n",
    "curves = dsua_112_utils.get_curves(q2e_gca)\n",
    "benchmark_curves = dsua_112_utils.get_curves(q2e_gca_benchmark)\n",
    "\n",
    "diff = dsua_112_utils.generate_normalized_difference(q2e_gca_benchmark, curves[\"Android\"], benchmark_curves['Android'])\n",
    "dsua_112_utils.compare_curves(diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "85da9b93b1e3f8cfbe517c5936ca6cdc",
     "grade": false,
     "grade_id": "q6-header",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3: Sentiment Analysis\n",
    "\n",
    "We can try to understand the sentiment behind the words in Trump's posts. For example, the sentence \"I love America!\" has positive sentiment. However, the sentence \"I hate taxes!\" has a negative sentiment. In addition, some words have stronger positive / negative sentiment than others: \"I love America.\" is more positive than \"I like America.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename=img_path + '/sentiment.PNG', embed=True, width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the [VADER (Valence Aware Dictionary and sEntiment Reasoner)](https://github.com/cjhutto/vaderSentiment) lexicon to analyze the sentiment of Trump's tweets. VADER is a lexicon and rule-based sentiment analysis tool that is specifically useful for sentiments in social media. The VADER lexicon gives the sentiment of individual words. Run the following cell to show the first few rows of the lexicon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b23c777c6099e2d80548342e725f1d44",
     "grade": false,
     "grade_id": "head-vader",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with open(lexicon_path) as fh:\n",
    "    print(''.join(fh.readlines()[:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that the lexicon contains contains words along with abbreviations, slang and emojis. Since some words can appear as abbreviations, the lexicon does include some duplication depending on context. For example, `lol` appears as both a word and abbreviation with sentiment. \n",
    "\n",
    "- The first column of the lexicon is the *token* meaning the word itself. \n",
    "- The second column is the *polarity* of the word meaning how positive / negative.  \n",
    "- The third columns is the standard deviation of the polarity\n",
    "- The fourth column are 10 raw scores determined by the annotators\n",
    "\n",
    "See the [documentation](https://github.com/cjhutto/vaderSentiment) for more information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "882ccc8f4112a4640114ca99e7d71d12",
     "grade": false,
     "grade_id": "q6a-header",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3a\n",
    "\n",
    "Use `pd.read_csv` to load the lexicon into a DataFrame called `sent`. \n",
    "\n",
    "- The index should be the tokens in the lexicon. \n",
    "- The table should have one column containing the polarity\n",
    "- The delimiter is `\\t` not `,` so you need to set `sep = \\t`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9afff75d794a62d1800d5f254d6e23e8",
     "grade": false,
     "grade_id": "q6a-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "path_to_use_for_sent = lexicon_path\n",
    "\n",
    "sent = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a700615b6cef141033080f4e00a4c3d1",
     "grade": true,
     "grade_id": "q6a-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "test",
     "q05a"
    ]
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "\n",
    "assert np.allclose(sent['polarity'].head(), [-1.5, -0.4, -1.5, -0.4, -0.7])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5dbfd0045b995ffe07aa8ae108c2e3f1",
     "grade": false,
     "grade_id": "q6b-header",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3b\n",
    "\n",
    "We want to use the lexicon to calculate the overall sentiment for each of Trump's tweets:\n",
    "\n",
    "1. For each tweet, find the sentiment of each word.\n",
    "2. Calculate the sentiment of each tweet by taking the sum of the sentiments of its words.\n",
    "\n",
    "First, let's lowercase the text in the tweets since the lexicon is also lowercase. Set the `text` column of the `trump` to be the lowercase text of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8bb2469a666ad8f1388abb6ad808881",
     "grade": false,
     "grade_id": "q6b-answer",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "58cf8943b671852543e9468492933632",
     "grade": true,
     "grade_id": "q6b-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "test",
     "q05b"
    ]
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert trump.loc[954722155463430145,\"text\"] == 'democrats are holding our military hostage over their desire to have unchecked illegal immigration. can’t let that happen!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b4ccc57f4d1746b08e68680aade01b11",
     "grade": false,
     "grade_id": "q6c-header",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3c\n",
    "\n",
    "We need to get rid of punctuation. Otherwise we won't match words in the lexicon. Create a new column called `no_punc` in`trump` to be the lowercase text of each tweet with all punctuation replaced by a single space. We consider punctuation characters to be any character that isn't a Unicode word character or a whitespace character. Remember that\n",
    "\n",
    "- The special character `\\w` denotes letters and numbers \n",
    "- The special character `\\s` denotes space\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2901325706be092abb437c239e7d3d83",
     "grade": false,
     "grade_id": "q6c",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Save your regex in punct_re\n",
    "punct_re = r''\n",
    "trump['no_punc'] = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "35a4c8c3839d2b6507092dd87a188722",
     "grade": true,
     "grade_id": "q6c-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "test",
     "q05c"
    ]
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "assert re.search(punct_re, 'this') is None\n",
    "assert re.search(punct_re, 'this is ok') is None\n",
    "assert re.search(punct_re, 'this is\\nok') is None\n",
    "assert re.search(punct_re, 'this is not ok.') is not None\n",
    "assert re.search(punct_re, 'this#is#ok') is not None\n",
    "assert re.search(punct_re, 'this^is ok') is not None\n",
    "\n",
    "assert trump['text'].loc[884740553040175104] == 'working hard to get the olympics for the united states (l.a.). stay tuned!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d1481c2b57abc42a5880ca6cd24fb0dc",
     "grade": false,
     "grade_id": "q6d-header",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3d:\n",
    "\n",
    "\n",
    "We should convert the tweets into a [*tidy format*](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html). Changing the format will help us to analyze the sentiments.  Use the `no_punc` column of `trump` to create a table called `tidy_format`. \n",
    "\n",
    "1. The index should be the `id` repeated once for every word in the tweet\n",
    "1. The first column should be called `num`. It should give the location of the word in the tweet. For example, if the tweet was \"i love america\", then the location of the word \"i\" is 0, \"love\" is 1, and \"america\" is 2.\n",
    "1. The second column should be called `word`. It should give the individual words of each tweet.\n",
    "\n",
    "Some rows of `tidy_format` table look like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>num</th>\n",
    "      <th>word</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>0</td>\n",
    "      <td>i</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>1</td>\n",
    "      <td>think</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>2</td>\n",
    "      <td>senator</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>3</td>\n",
    "      <td>blumenthal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>4</td>\n",
    "      <td>should</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Since we should avoid using loops, we will take advantage of `pandas` methods. We will take three steps. \n",
    "\n",
    "First we use a string method called `split` that breaks the words across different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8d07f1401026cf045a1f5da38e89e22f",
     "grade": false,
     "grade_id": "cell-8721cc32daa1d2d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Step 1\n",
    "\n",
    "no_punc_split = trump[\"no_punc\"].str.split(expand = True)\n",
    "\n",
    "no_punc_split.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c896c5c8bf27caefb3d4cb2d9ed22126",
     "grade": false,
     "grade_id": "cell-47903b24b13249f4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Second we use a method called `melt`. Remember that we discussed `melt` in Week 6 lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "624fd75c53653eddee4b5bbf7f7944c3",
     "grade": false,
     "grade_id": "cell-0d826a3f9c358c96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "\n",
    "numbered_columns = no_punc_split.columns.values\n",
    "no_punc_split.reset_index(inplace = True)\n",
    "\n",
    "tidy_format = pd.melt(no_punc_split, id_vars=['id'], value_vars=numbered_columns)\n",
    "\n",
    "tidy_format.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "75ceaf00dfb7a8f44ca5f9d913b6a254",
     "grade": false,
     "grade_id": "cell-6aa0e67b1e6e0d4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Third we need to \n",
    "\n",
    "- Rename `variable` column to `num`\n",
    "- Rename `value` column to `word`\n",
    "- Drop any rows with missing values\n",
    "- Sort by `['id','variable']`\n",
    "- Set index to be the `id` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c6b1bf3d9d3e392df603e94911e6700e",
     "grade": false,
     "grade_id": "cell-0ac743675480a242",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3466cc6fa98785f75c4e4dfba0200457",
     "grade": true,
     "grade_id": "q6d-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "test",
     "q05d"
    ]
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "assert tidy_format.loc[894661651760377856].shape == (27, 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "37e7ee226c5d4ef6a96ad576df6ed5ee",
     "grade": false,
     "grade_id": "q6e-header",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3e:\n",
    "\n",
    "Now that we have changed the format, we can study the sentiment of each tweet. In particular, we can join the table with the lexicon table. \n",
    "\n",
    "Add a `polarity` column to the `trump` table.  The `polarity` column should contain the sum of the sentiment polarity of each word in the text of the tweet.\n",
    "\n",
    "- Take a left join of `tidy_format` and `sent`\n",
    "- Fill missing values with 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a85f8ad66fad260d490cd2aeb5aaf11",
     "grade": false,
     "grade_id": "cell-8ba81c586662ab14",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tidy_format_sent_merged = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "725c96a5dd3afe501a6c41f552e992b2",
     "grade": true,
     "grade_id": "cell-64bb349a8d4ec3b0",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert tidy_format_sent_merged[\"polarity\"].isna().sum() == 0\n",
    "assert set(tidy_format_sent_merged.columns.values).issubset({\"polarity\", \"word\", \"num\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98894ef6aea8196bf2f068690cc0b8fe",
     "grade": false,
     "grade_id": "cell-865cca6cdb63c66f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Group `tidy_format_sent_merged` by `id`. Use `agg` on the `polarity` column with the `sum` function to add the numbers for each post. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ad778cbb8a86c9255acac2d8799fa96",
     "grade": false,
     "grade_id": "q6e",
     "locked": false,
     "schema_version": 3,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "trump['polarity'] = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc587c31456e6f05dcc237fadc9a9dd4",
     "grade": true,
     "grade_id": "q6e-tests",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "test",
     "q05e"
    ]
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "assert np.allclose(trump.loc[744701872456536064, 'polarity'], 8.4)\n",
    "assert np.allclose(trump.loc[745304731346702336, 'polarity'], 2.5)\n",
    "assert np.allclose(trump.loc[744519497764184064, 'polarity'], 1.7)\n",
    "# If you fail this test, you dropped tweets with 0 polarity\n",
    "assert np.allclose(trump.loc[744355251365511169, 'polarity'], 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab3d5d150129d76a01f9cc60f5ef6f2f",
     "grade": false,
     "grade_id": "a-note-on-vader",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Now we have a measure of the sentiment of each of his tweets. Run the cells below to see the most positive and most negative tweets from Trump in your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3ea0c421557a05c5a03c51515a5fdc78",
     "grade": false,
     "grade_id": "negative-tweets",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print('Most negative tweets:')\n",
    "for t in trump.sort_values('polarity').head()['text']:\n",
    "    print('\\n  ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e0d27a82de94a1ce5cf64a2c72ffb7aa",
     "grade": false,
     "grade_id": "postive-tweets",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print('Most positive tweets:')\n",
    "for t in trump.sort_values('polarity', ascending=False).head()['text']:\n",
    "    print('\\n  ', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fec34d576718004588a590465872b1eb",
     "grade": false,
     "grade_id": "q6g",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 3f\n",
    "\n",
    "Plot the distribution of tweet sentiments broken down by whether the text of the tweet contains `nyt` or `fox`.  You should obtain a chart like the followig."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "39485db7bdf28d26c35446a9044f12ff",
     "grade": false,
     "grade_id": "cell-34dd8aebb8729f25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=img_path + '/news.PNG', embed=True, width=750)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "400b701e6d3131321201fe965a3205bb",
     "grade": false,
     "grade_id": "cell-e1077213ab36b2cb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "keywords = [\"nyt\",\"fox\"]\n",
    "\n",
    "for keyword in keywords:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "plt.legend()\n",
    "q3f_gca = plt.gca();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18bcdb67aafea8db419903aca3e70c4f",
     "grade": true,
     "grade_id": "cell-4fcbcabee5c0ebec",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "heights = [rect.get_height() for rect in q3f_gca.get_children() if isinstance(rect,matplotlib.patches.Rectangle)]\n",
    "\n",
    "assert np.isclose(sorted(heights)[-2], 0.32, atol = 1e-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b7368fe0c0258f888dcd1108c0388375",
     "grade": false,
     "grade_id": "q7-header2",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 4: Engagement\n",
    "\n",
    "We want to understand the posts that led to many retweets. If a post was retweeted, then a follow of Donald Trump copied the post to a different user. The keywords in these posts should indicate topics of interests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84f69f2a08da5614dda56ed3ac72aed9",
     "grade": false,
     "grade_id": "cell-5721f8911e2b981b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=img_path + '/keywords.PNG', embed=True, width=750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a1555a951e38ab8058f4c0a317f27259",
     "grade": false,
     "grade_id": "q7-header4",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 4a\n",
    "\n",
    "We will determine the words that led to many retweets on average. For example, at the time of this writing, Donald Trump has two tweets that contain the word 'oakland' (tweets 932570628451954688 and 1016609920031117312) with 36757 and 10286 retweets respectively, for an average of 23,521.5.\n",
    "\n",
    "We will take four steps to find the 20 most retweeted words. We will include only words that appear in at least 25 tweets. The format of `top_20` table will be\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>retweet_count</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>word</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>jong</th>\n",
    "      <td>40592.833333</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>क</th>\n",
    "      <td>37918.307692</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>iranian</th>\n",
    "      <td>32982.000000</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "      <th>un</th>\n",
    "      <td>32677.024390</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>kim</th>\n",
    "      <td>32237.306122</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "Note that the table will contain some words outside of the Latin alphabet. Surrounding a visit to India, some posts include characters from Devanagari a block of Unicode containing alphabets such as Hindi.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c7e6414a2e404cd7a2afc9d07428831a",
     "grade": false,
     "grade_id": "cell-1b109b378446a052",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, we can use the `tidy_format_sent_merged` table from Question 3 to study the words in each post. Joining with the `retweet_count` column of `trump` gives us the number of retweets of the post for each word in the post. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdcceedd1f8c01acac8d8284630d702a",
     "grade": false,
     "grade_id": "cell-a5c72670bc40b4ce",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Step 1 \n",
    "\n",
    "retweets = pd.merge(left = trump[[\"retweet_count\"]], \n",
    "                    right = tidy_format_sent_merged, \n",
    "                    left_index = True, \n",
    "                    right_index = True, \n",
    "                    how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b5c80d7e3bee7cfe0dde465cbc85ff00",
     "grade": false,
     "grade_id": "cell-93f212df800c686a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Second group `retweets` by `word`. Use filter to remove any words that appear fewer than 25 times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e65e1838cc3ab4433e348b5403aa8a6",
     "grade": false,
     "grade_id": "cell-30b570ec2b8a06f4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "\n",
    "retweets_filtered = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7272946567b8652080d0513649d0ae0b",
     "grade": true,
     "grade_id": "cell-36db86da96d02646",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert retweets_filtered.groupby(\"word\").size().min() > 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e22f273da63479c72a2460f0906ca55a",
     "grade": false,
     "grade_id": "cell-935dca96779a1702",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Third group `retweets_filtered` by `word`. We can use `agg` to compute the average of the `retweet_count` column in each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd94453c93ce54c2ac0cbc49d09a1197",
     "grade": false,
     "grade_id": "cell-5cd5cd8bcde31515",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "\n",
    "retweets_average = ...\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c9a203844b6126d823a597633d853296",
     "grade": true,
     "grade_id": "cell-ef3cfbdcb0a63db4",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TEST \n",
    "\n",
    "assert retweets_average.index.name == \"word\"\n",
    "assert retweets_average.columns.values == [\"retweet_count\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "223e4bca2632bb175b26d05aa4907ea0",
     "grade": false,
     "grade_id": "cell-505885ec1fd5d62e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now that we have the average number of retweets in `retweets_average`, use `sort_values` to determine the top 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9e9971296c5b9628d7e4d16c46a31128",
     "grade": false,
     "grade_id": "cell-ef237a23a96e4ad7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Step 4\n",
    "\n",
    "top_20 = ... \n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f2b7fc8dc39f1638be99cbb47ea6aeb",
     "grade": true,
     "grade_id": "q7a-test",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false
    },
    "tags": [
     "test",
     "q07a"
    ]
   },
   "outputs": [],
   "source": [
    "#TEST\n",
    "assert 'iran'     in top_20.index\n",
    "assert 'nuclear' in top_20.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4a12be8f88ac931b51b85a1ffa5cfde",
     "grade": false,
     "grade_id": "bar-chart-results",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "Here's a bar chart of your results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "473ca06f3c512859c324d1a605c58ca1",
     "grade": false,
     "grade_id": "top-retweets",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "top_20['retweet_count'].plot.barh();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3c03e453ac0c2f6bb3d0db2beb762f0f",
     "grade": false,
     "grade_id": "q7b",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Question 4b\n",
    "\n",
    "At some point in time, \"kim\", \"jong\" and \"un\" were popular in Trump's tweets. Can we concludet that tweets involving \"jong\" are more popular than his other tweets. \n",
    "\n",
    "Consider each of the statements about possible confounding factors below. State whether each statement is true or false and explain. If the statement is true, state whether the confounding factor could have made kim jong un related tweets higher in the list than they should be.\n",
    "\n",
    "1. We didn't restrict our word list to nouns, so we have unhelpful words like \"let\" and \"any\" in our result.\n",
    "1. We didn't remove hashtags in our text, so we have duplicate words (eg. #great and great).\n",
    "1. We didn't account for the fact that Trump's follower count has increased over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "#### YOUR ANSWER HERE\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsua-112]",
   "language": "python",
   "name": "conda-env-dsua-112-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
